{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed referances\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Shuffle the datasets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "#import seaborn as sns\n",
    "#Output plots in notebook\n",
    "#%matplotlib inline \n",
    "\n",
    "addpoly = True\n",
    "plot_lc = 0   # 1--display learning curve/ 0 -- don't display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------load train & test file------\n",
      "train dataset: (891, 12), test dataset (418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the data sets from the csv files\n",
    "print('--------load train & test file------')\n",
    "train_dataset = pd.read_csv('train.csv')\n",
    "test_dataset = pd.read_csv('test.csv')\n",
    "\n",
    "print('train dataset: %s, test dataset %s' %(str(train_dataset.shape), str(test_dataset.shape)) )\n",
    "train_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id is unique.\n",
      "Train and test sets are distinct.\n",
      "oops we have nan\n"
     ]
    }
   ],
   "source": [
    "print('Id is unique.') if train_dataset.PassengerId.nunique() == train_dataset.shape[0] else print('oops')\n",
    "print('Train and test sets are distinct.') if len(np.intersect1d(train_dataset.PassengerId.values, test_dataset.PassengerId.values))== 0 else print('oops')\n",
    "# print('We do not need to worry about missing values.') if train_dataset.count().min() == train_dataset.shape[0] and test_dataset.count().min() == test_dataset.shape[0] else print('oops we have nan')\n",
    "\n",
    "datasetHasNan = False\n",
    "if train_dataset.count().min() == train_dataset.shape[0] and test_dataset.count().min() == test_dataset.shape[0] :\n",
    "    print('We do not need to worry about missing values.') \n",
    "else:\n",
    "    datasetHasNan = True\n",
    "    print('oops we have nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train dataset column types information-------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Type</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>object</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column Type  Count\n",
       "0       int64      5\n",
       "1     float64      2\n",
       "2      object      5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('----train dataset column types information-------')\n",
    "dtype_df = train_dataset.dtypes.reset_index()\n",
    "dtype_df.columns = [\"Count\", \"Column Type\"]\n",
    "dtype_df.groupby(\"Column Type\").aggregate('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train dataset information-------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Column Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count Column Type\n",
       "0   PassengerId       int64\n",
       "1      Survived       int64\n",
       "2        Pclass       int64\n",
       "3          Name      object\n",
       "4           Sex      object\n",
       "5           Age     float64\n",
       "6         SibSp       int64\n",
       "7         Parch       int64\n",
       "8        Ticket      object\n",
       "9          Fare     float64\n",
       "10        Cabin      object\n",
       "11     Embarked      object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('----train dataset information-------')\n",
    "dtype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan in the data sets\n",
      "          Train Dataset  Test Dataset\n",
      "Age                 177          86.0\n",
      "Cabin               687         327.0\n",
      "Embarked              2           0.0\n",
      "Fare                  0           1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Md Farzad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Check for missing data & list them \n",
    "if datasetHasNan == True:\n",
    "    nas = pd.concat([train_dataset.isnull().sum(), test_dataset.isnull().sum()], axis=1, keys=['Train Dataset', 'Test Dataset']) \n",
    "    print('Nan in the data sets')\n",
    "    print(nas[nas.sum(axis=1) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "# Class vs Survived\n",
    "print(train_dataset[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n"
     ]
    }
   ],
   "source": [
    "# sex vs Survived\n",
    "print(train_dataset[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SibSp  Survived\n",
      "1      1  0.535885\n",
      "2      2  0.464286\n",
      "0      0  0.345395\n",
      "3      3  0.250000\n",
      "4      4  0.166667\n",
      "5      5  0.000000\n",
      "6      8  0.000000\n"
     ]
    }
   ],
   "source": [
    "# SibSp vs Survived\n",
    "#Sibling = brother, sister, stepbrother, stepsister\n",
    "#Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "print(train_dataset[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parch  Survived\n",
      "3      3  0.600000\n",
      "1      1  0.550847\n",
      "2      2  0.500000\n",
      "0      0  0.343658\n",
      "5      5  0.200000\n",
      "4      4  0.000000\n",
      "6      6  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Parch vs Survived\n",
    "#Parent = mother, father\n",
    "#Child = daughter, son, stepdaughter, stepson\n",
    "#Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "print(train_dataset[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Strat data cleaning ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Md Farzad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Md Farzad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Data sets cleaing, fill nan (null) where needed and delete uneeded columns\n",
    "print('----Strat data cleaning ------------')\n",
    "\n",
    "#train_dataset['IsMinor'] = 0\n",
    "#train_dataset.loc[(train_dataset['Age'] < 14) & ((train_dataset['Pclass'] == 1) | (train_dataset['Pclass'] == 2) ), 'IsMinor'] = 1\n",
    "\n",
    "#test_dataset['IsMinor'] = 0\n",
    "#test_dataset.loc[(test_dataset['Age'] < 14) & ((test_dataset['Pclass'] == 1 ) | (test_dataset['Pclass'] == 2 )), 'IsMinor'] = 1\n",
    "\n",
    "\n",
    "#manage Age\n",
    "train_random_ages = np.random.randint(train_dataset[\"Age\"].mean() - train_dataset[\"Age\"].std(),\n",
    "                                          train_dataset[\"Age\"].mean() + train_dataset[\"Age\"].std(),\n",
    "                                          size = train_dataset[\"Age\"].isnull().sum())\n",
    "\n",
    "test_random_ages = np.random.randint(test_dataset[\"Age\"].mean() - test_dataset[\"Age\"].std(),\n",
    "                                          test_dataset[\"Age\"].mean() + test_dataset[\"Age\"].std(),\n",
    "                                          size = test_dataset[\"Age\"].isnull().sum())\n",
    "\n",
    "train_dataset[\"Age\"][np.isnan(train_dataset[\"Age\"])] = train_random_ages\n",
    "test_dataset[\"Age\"][np.isnan(test_dataset[\"Age\"])] = test_random_ages\n",
    "train_dataset['Age'] = train_dataset['Age'].astype(int)\n",
    "test_dataset['Age']    = test_dataset['Age'].astype(int)\n",
    "\n",
    "# Embarked \n",
    "train_dataset[\"Embarked\"].fillna('S', inplace=True)\n",
    "test_dataset[\"Embarked\"].fillna('S', inplace=True)\n",
    "train_dataset['Port'] = train_dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "test_dataset['Port'] = test_dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "del train_dataset['Embarked']\n",
    "del test_dataset['Embarked']\n",
    "\n",
    "# Fare\n",
    "test_dataset[\"Fare\"].fillna(test_dataset[\"Fare\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train_dataset['Has_Cabin'] = train_dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test_dataset['Has_Cabin'] = test_dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# engineer a new Title feature\n",
    "# group them\n",
    "full_dataset = [train_dataset, test_dataset]\n",
    "\n",
    "##engineer the family size feature\n",
    "for dataset in full_dataset:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "### new try \n",
    "\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_dataset:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "##############################\n",
    "\n",
    "\n",
    "# Get titles from the names\n",
    "train_dataset['Title'] = train_dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_dataset['Title'] = test_dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "for dataset in full_dataset:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "\n",
    "    \n",
    "## Create new column \"FamilySizeGroup\" and assign \"Alone\", \"Small\" and \"Big\"\n",
    "for dataset in full_dataset:\n",
    "    dataset['FamilySizeGroup'] = 'Small'\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'FamilySizeGroup'] = 'Alone'\n",
    "    dataset.loc[dataset['FamilySize'] >= 5, 'FamilySizeGroup'] = 'Big'\n",
    "\n",
    "## Get the average survival rate of different FamilySizes\n",
    "train_dataset[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean()\n",
    "\n",
    "for dataset in full_dataset:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "        \n",
    "for dataset in full_dataset:    \n",
    "    dataset.loc[ dataset['Age'] <= 14, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 14) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "for dataset in full_dataset:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Finish data cleaning ------------\n"
     ]
    }
   ],
   "source": [
    "# map the new features\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "family_mapping = {\"Small\": 0, \"Alone\": 1, \"Big\": 2}\n",
    "for dataset in full_dataset:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['FamilySizeGroup'] = dataset['FamilySizeGroup'].map(family_mapping)\n",
    "\n",
    "# engineer a new  features\n",
    "for dataset in full_dataset:\n",
    "    dataset['IsChildandRich'] = 0\n",
    "    dataset.loc[(dataset['Age'] <= 0) & (dataset['Pclass'] == 1 ),'IsChildandRich'] = 1  \n",
    "    dataset.loc[(dataset['Age'] <= 0) & (dataset['Pclass'] == 2 ),'IsChildandRich'] = 1  \n",
    "    \n",
    "#for dataset in full_dataset:\n",
    "#    dataset['Age*Class'] = dataset.Age * dataset.Pclass \n",
    "\n",
    "\n",
    "#for dataset in full_dataset:\n",
    "#    dataset['Sex*Class'] = dataset.Sex * dataset.Pclass \n",
    "\n",
    "#for dataset in full_dataset:\n",
    "#    dataset['Sex*Age'] = dataset.Sex * dataset.Age \n",
    "    \n",
    "#for dataset in full_dataset:\n",
    "#    dataset['Age*Class*Sex'] = (dataset.Age * dataset.Pclass) + dataset.Sex\n",
    "\n",
    "for data in full_dataset:\n",
    "    # classify Cabin by fare\n",
    "    data['Cabin'] = data['Cabin'].fillna('X')\n",
    "    data['Cabin'] = data['Cabin'].apply(lambda x: str(x)[0])\n",
    "    data['Cabin'] = data['Cabin'].replace(['A', 'D', 'E', 'T'], 'M')\n",
    "    data['Cabin'] = data['Cabin'].replace(['B', 'C'], 'H')\n",
    "    data['Cabin'] = data['Cabin'].replace(['F', 'G'], 'L')\n",
    "    data['Cabin'] = data['Cabin'].map({'X': 0, 'L': 1, 'M': 2, 'H': 3}).astype(int) \n",
    "    #data['Cabin'].loc[~data['Cabin'].isnull()] = 1\n",
    "    #data['Cabin'].loc[data['Cabin'].isnull()] = 0\n",
    "\n",
    "    \n",
    "# Delete Name column from datasets (No need for them in the analysis)\n",
    "del train_dataset['Name']\n",
    "del test_dataset['Name']\n",
    "\n",
    "del train_dataset['SibSp']\n",
    "del test_dataset['SibSp']\n",
    "\n",
    "del train_dataset['Parch']\n",
    "del test_dataset['Parch']\n",
    "\n",
    "del train_dataset['FamilySize']\n",
    "del test_dataset['FamilySize']\n",
    "\n",
    "#del train_dataset['FamilySizeGroup']\n",
    "#del test_dataset['FamilySizeGroup']\n",
    "\n",
    "del train_dataset['Cabin']\n",
    "del test_dataset['Cabin']\n",
    "\n",
    "# Delete Ticket column from datasets  (No need for them in the analysis)\n",
    "del train_dataset['Ticket']\n",
    "del test_dataset['Ticket']\n",
    "\n",
    "del train_dataset['Port']\n",
    "del test_dataset['Port']\n",
    "\n",
    "\n",
    "# Cabin has a lot of nan values, so i will remove it\n",
    "#del train_dataset['Cabin']\n",
    "#del test_dataset['Cabin']\n",
    "\n",
    "##title_dummies_titanic  = pd.get_dummies(train_dataset['Title'])\n",
    "##train_dataset = train_dataset.join(title_dummies_titanic)\n",
    "##\n",
    "##title_dummies_titanic  = pd.get_dummies(test_dataset['Title'])\n",
    "##test_dataset = test_dataset.join(title_dummies_titanic)\n",
    "##\n",
    "### Drop\n",
    "##train_dataset.drop(['Title'], axis=1,inplace=True)\n",
    "##test_dataset.drop(['Title'], axis=1,inplace=True)\n",
    "\n",
    "\n",
    "print('----Finish data cleaning ------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: (891, 11), test dataset (418, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySizeGroup</th>\n",
       "      <th>IsChildandRich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  Fare  Has_Cabin  IsAlone  Title  \\\n",
       "0            1         0       3    0    1     0          0        0      1   \n",
       "1            2         1       1    1    2     3          1        0      3   \n",
       "2            3         1       3    1    1     1          0        1      2   \n",
       "3            4         1       1    1    2     3          1        0      3   \n",
       "4            5         0       3    0    2     1          0        1      1   \n",
       "\n",
       "   FamilySizeGroup  IsChildandRich  \n",
       "0                0               0  \n",
       "1                0               0  \n",
       "2                1               0  \n",
       "3                0               0  \n",
       "4                1               0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train dataset: %s, test dataset %s' %(str(train_dataset.shape), str(test_dataset.shape)) )\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891,)\n",
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "del train_dataset['PassengerId']\n",
    "\n",
    "#X_train = train_dataset.drop(\"Survived\",axis=1).as_matrix()\n",
    "#Y_train = train_dataset[\"Survived\"].as_matrix()\n",
    "#X_test  = test_dataset.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "\n",
    "X_train = train_dataset.drop(\"Survived\",axis=1)\n",
    "Y_train = train_dataset[\"Survived\"]\n",
    "X_test  = test_dataset.drop(\"PassengerId\",axis=1).copy()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 55)\n",
      "(891,)\n",
      "(418, 55)\n"
     ]
    }
   ],
   "source": [
    "### try polynomials:\n",
    "from sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n",
    "\n",
    "if addpoly:\n",
    "    all_data = pd.concat((X_train,\n",
    "                          X_test), ignore_index=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(all_data)\n",
    "    all_data=scaler.transform(all_data)\n",
    "    poly = PolynomialFeatures(2)\n",
    "    all_data=poly.fit_transform(all_data)\n",
    "\n",
    "    X_train = all_data[:train_dataset.shape[0]]\n",
    "    X_test = all_data[train_dataset.shape[0]:]\n",
    "    ##\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "logreg_model = LogisticRegression()\n",
    "def Learning_curve_model(X, Y, model, cv, train_sizes):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, Y, cv=cv, n_jobs=4, train_sizes=train_sizes)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std  = np.std(train_scores, axis=1)\n",
    "    test_scores_mean  = np.mean(test_scores, axis=1)\n",
    "    test_scores_std   = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "                     \n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "#learn curve\n",
    "if plot_lc==1:\n",
    "    train_size=np.linspace(.1, 1.0, 15)\n",
    "    Learning_curve_model(X_train,Y_train , logreg_model, cv, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taring score = 0.8338945005611672 , while validation score = 0.8159541837734551\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression() #(C=0.1, penalty='l1', tol=1e-6)\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "result_train = logreg.score(X_train, Y_train)\n",
    "result_val = cross_val_score(logreg,X_train, Y_train, cv=5).mean()\n",
    "print('taring score = %s , while validation score = %s' %(result_train , result_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taring score = 0.8237934904601572 , while validation score = 0.8226769965249149\n"
     ]
    }
   ],
   "source": [
    "### Support Vector Machines\n",
    "##\n",
    "###from sklearn import svm, grid_search\n",
    "###from sklearn.grid_search import GridSearchCV\n",
    "###Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "###gammas = [0.001, 0.01, 0.1, 1]\n",
    "###param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "###grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=5)\n",
    "###grid_search.fit(X_train, Y_train)\n",
    "###print(grid_search.best_params_)\n",
    "##\n",
    "svc = SVC(C = 0.1, gamma=0.1)\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "\n",
    "result_train = svc.score(X_train, Y_train)\n",
    "result_val = cross_val_score(svc,X_train, Y_train, cv=5).mean()\n",
    "print('taring score = %s , while validation score = %s' %(result_train , result_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taring score = 0.8417508417508418 , while validation score = 0.8215912052931656\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "\n",
    "random_forest = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=1000,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "seed= 42\n",
    "random_forest =RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=5, min_samples_split=2,\n",
    "                           min_samples_leaf=1, max_features='auto',    bootstrap=False, oob_score=False, \n",
    "                           n_jobs=1, random_state=seed,verbose=0)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "result_train = random_forest.score(X_train, Y_train)\n",
    "result_val = cross_val_score(random_forest,X_train, Y_train, cv=5).mean()\n",
    "\n",
    "print('taring score = %s , while validation score = %s' %(result_train , result_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_dataset[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)\n",
    "print('Exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
